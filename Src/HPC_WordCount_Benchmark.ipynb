{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipFgwRk3xM00",
        "outputId": "d684a0c3-386d-4b33-bcc5-3d34f50625f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T_serial: 0.0506s\n",
            "T_p1: 0.0516s\n",
            "T_pN (2 threads): 0.0532s\n",
            "Speedup: 0.95\n",
            "Relative Speedup: 0.97\n",
            "Efficiency: 0.48\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import threading\n",
        "import os\n",
        "import multiprocessing\n",
        "from collections import Counter\n",
        "\n",
        "def count_words(text):\n",
        "    return Counter(text.split())\n",
        "\n",
        "def run_serial(text):\n",
        "    t0 = time.time()\n",
        "    _ = count_words(text)\n",
        "    return time.time() - t0\n",
        "\n",
        "def run_parallel(text, num_threads):\n",
        "    words = text.split()\n",
        "    n = len(words)\n",
        "    chunk = n // num_threads\n",
        "    parts = []\n",
        "    for i in range(num_threads):\n",
        "        start = i * chunk\n",
        "        end = (i + 1) * chunk if i != num_threads - 1 else n\n",
        "        parts.append(\" \".join(words[start:end]))\n",
        "\n",
        "    results = [None] * num_threads\n",
        "    threads = []\n",
        "    t0 = time.time()\n",
        "    for i in range(num_threads):\n",
        "        th = threading.Thread(target=lambda idx, part: results.__setitem__(idx, count_words(part)), args=(i, parts[i]))\n",
        "        threads.append(th)\n",
        "        th.start()\n",
        "    for th in threads:\n",
        "        th.join()\n",
        "    t_elapsed = time.time() - t0\n",
        "    return t_elapsed\n",
        "\n",
        "def main():\n",
        "    path = \"wordcount_sample_2MB.txt\"  # default file\n",
        "    if not os.path.exists(path):\n",
        "        print(\"File not found.\")\n",
        "        return\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # --- change fraction here to use part of the data ---\n",
        "    fraction = 1.0  # 1.0 = 100%, 0.5 = 50%, 0.25 = 25%, etc.\n",
        "    words = text.split()\n",
        "    cut = int(len(words) * fraction)\n",
        "    text = \" \".join(words[:cut])\n",
        "\n",
        "    num_threads = multiprocessing.cpu_count()\n",
        "\n",
        "    t_serial = run_serial(text)\n",
        "    t_p1 = run_parallel(text, 1)\n",
        "    t_pN = run_parallel(text, num_threads)\n",
        "\n",
        "    speedup = t_serial / t_pN if t_pN > 0 else float('inf')\n",
        "    rel_speedup = t_p1 / t_pN if t_pN > 0 else float('inf')\n",
        "    efficiency = speedup / num_threads if num_threads > 0 else 0.0\n",
        "\n",
        "    print(f\"T_serial: {t_serial:.4f}s\")\n",
        "    print(f\"T_p1: {t_p1:.4f}s\")\n",
        "    print(f\"T_pN ({num_threads} threads): {t_pN:.4f}s\")\n",
        "    print(f\"Speedup: {speedup:.2f}\")\n",
        "    print(f\"Relative Speedup: {rel_speedup:.2f}\")\n",
        "    print(f\"Efficiency: {efficiency:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}